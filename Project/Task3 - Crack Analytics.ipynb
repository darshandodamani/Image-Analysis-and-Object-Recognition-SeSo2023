{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task3 - Crack Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crack segmentation unfolds its power only when the results undergo further processing. Information such as the length or the number of branches of a crack are crucial for the assessment of a structureâ€™s condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Implement a metric to assess the performance of the implemented approach. The standard metric for semantic segmentation is intersection-over-union (IoU). Report the performance of the detector on the test set and discuss the adequacy of the metric for crack detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.measure import regionprops\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the input images\n",
    "input_dir = \"dataset/crack\"\n",
    "\n",
    "# Directory to save the processed images\n",
    "output_dir = \"dataset/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# List all image files in the input directory\n",
    "image_files = [f for f in os.listdir(input_dir) if f.endswith((\".png\"))]\n",
    "\n",
    "# Define a kernel for morphological operations\n",
    "kernel = np.ones((3, 3), np.uint8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store feature vectors and labels\n",
    "feature_vectors = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform connected component analysis\n",
    "def connected_component_analysis(image):\n",
    "    # Initialize equivalent label table and label counter\n",
    "    equivalent_labels = {}\n",
    "    label_counter = 0\n",
    "\n",
    "    # Create a function to find the root label of an equivalence group\n",
    "    def find_root_label(label):\n",
    "        if label in equivalent_labels:\n",
    "            return find_root_label(equivalent_labels[label])\n",
    "        else:\n",
    "            return label\n",
    "\n",
    "    # Process the image row by row and label connected components\n",
    "    for y in range(image.shape[0]):\n",
    "        for x in range(image.shape[1]):\n",
    "            # Check if the current pixel is foreground (crack)\n",
    "            if image[y, x] == 255:\n",
    "                # Get the labels of the neighboring pixels\n",
    "                neighbors = []\n",
    "\n",
    "                if x > 0 and image[y, x - 1] == 255:\n",
    "                    neighbors.append(image[y, x - 1])\n",
    "\n",
    "                if y > 0 and image[y - 1, x] == 255:\n",
    "                    neighbors.append(image[y - 1, x])\n",
    "\n",
    "                # If there are no neighboring foreground pixels, assign a new label\n",
    "                if not neighbors:\n",
    "                    label_counter += 1\n",
    "                    image[y, x] = label_counter\n",
    "                else:\n",
    "                    # Assign the smallest label among neighbors\n",
    "                    min_neighbor_label = min(neighbors)\n",
    "                    image[y, x] = min_neighbor_label\n",
    "\n",
    "                    # Update the equivalent label table\n",
    "                    for neighbor in neighbors:\n",
    "                        if neighbor != min_neighbor_label:\n",
    "                            root_label = find_root_label(neighbor)\n",
    "                            equivalent_labels[root_label] = min_neighbor_label\n",
    "\n",
    "    # Perform a second pass to update labels with equivalent labels\n",
    "    for y in range(image.shape[0]):\n",
    "        for x in range(image.shape[1]):\n",
    "            label = image[y, x]\n",
    "            if label in equivalent_labels:\n",
    "                image[y, x] = find_root_label(label)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_file in image_files:\n",
    "    # Load the image\n",
    "    img = cv2.imread(os.path.join(input_dir, image_file))\n",
    "\n",
    "    # Calculate minimum and maximum pixel values\n",
    "    min_val = np.min(img)\n",
    "    max_val = np.max(img)\n",
    "\n",
    "    # Vectorized operations for contrast stretching\n",
    "    contrast_stretching = 255 * ((img - min_val) / (max_val - min_val))\n",
    "\n",
    "    # Round the pixel values to the nearest integer\n",
    "    contrast_stretching = np.round(contrast_stretching)\n",
    "\n",
    "    # Ensure pixel values are in the range [0, 255]\n",
    "    contrast_stretching = np.clip(contrast_stretching, 0, 255)\n",
    "    contrast_stretching = contrast_stretching.astype('uint8')\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(contrast_stretching, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply adaptive thresholding to obtain a binary image\n",
    "    binary_image = cv2.adaptiveThreshold(\n",
    "        gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2\n",
    "    )\n",
    "\n",
    "    # Apply morphological operations\n",
    "    # 1. Dilation to connect nearby cracks and make them thicker\n",
    "    dilated_image = cv2.dilate(binary_image, kernel, iterations=1)\n",
    "\n",
    "    # 2. Erosion to remove noise and thin out the cracks slightly\n",
    "    eroded_image = cv2.erode(dilated_image, kernel, iterations=1)\n",
    "\n",
    "    # Perform connected component analysis to label regions\n",
    "    labeled_image = connected_component_analysis(eroded_image)\n",
    "\n",
    "    # 3. Closing to further connect cracks\n",
    "    closing_image = cv2.morphologyEx(eroded_image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # 4. Morphological thinning using scikit-image\n",
    "    thinned_image = skeletonize(closing_image)\n",
    "\n",
    "    # Extract feature vectors and labels\n",
    "    ground_truth = cv2.imread(os.path.join(input_dir, image_file), cv2.IMREAD_GRAYSCALE)\n",
    "    for region in regionprops(labeled_image):\n",
    "        area = region.area\n",
    "        perimeter = region.perimeter\n",
    "        if perimeter != 0:\n",
    "            circularity = 4 * np.pi * (area / (perimeter**2))\n",
    "        else:\n",
    "            circularity = 0.0\n",
    "        is_crack = ground_truth[int(region.centroid[1]), int(region.centroid[0])] == 255\n",
    "        feature_vector = [area, perimeter, circularity]\n",
    "        feature_vectors.append(feature_vector)\n",
    "        labels.append(is_crack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (e.g., 80% training, 20% testing) as given in Project\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_vectors, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the rule-based classifier: 95.61%\n"
     ]
    }
   ],
   "source": [
    "# classifier\n",
    "def rule_based_classifier(feature_vector):\n",
    "    area, perimeter, circularity = feature_vector\n",
    "    if circularity > 0.5:\n",
    "        return True  # Predict as crack\n",
    "    else:\n",
    "        return False  # Predict as non-crack\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "correct_predictions = 0\n",
    "total_predictions = len(X_test)\n",
    "\n",
    "for i in range(total_predictions):\n",
    "    predicted_label = rule_based_classifier(X_test[i])\n",
    "    if predicted_label == y_test[i]:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = (correct_predictions / total_predictions) * 100\n",
    "print(f\"Accuracy of the rule-based classifier: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "IoU: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to keep track of true positives, false positives, and false negatives\n",
    "true_positives = 0\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "\n",
    "# Define a threshold for classifying regions as cracks\n",
    "iou_threshold = 0.4\n",
    "# Iterate through the test set\n",
    "for i in range(len(X_test)):\n",
    "    predicted_label = rule_based_classifier(X_test[i])  # Apply your classifier\n",
    "    true_label = y_test[i]\n",
    "    \n",
    "    # Calculate IoU for the current region\n",
    "    if predicted_label and true_label:\n",
    "        intersection = np.logical_and(predicted_label, true_label)\n",
    "        union = np.logical_or(predicted_label, true_label)\n",
    "        iou = np.sum(intersection) / np.sum(union)\n",
    "        \n",
    "        # Update TP, FP, and FN based on IoU and threshold\n",
    "        if iou > iou_threshold:\n",
    "            true_positives += 1\n",
    "        else:\n",
    "            false_positives += 1\n",
    "    elif predicted_label and not true_label:\n",
    "        false_positives += 1\n",
    "    elif not predicted_label and true_label:\n",
    "        false_negatives += 1\n",
    "\n",
    "# Calculate precision, recall, and IoU\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "iou = true_positives / (true_positives + false_positives + false_negatives)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"IoU: {iou:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) For further processing use thinning in order to reduced the segmentation results to a line-like representation of the crack. You are allowed to use built-in functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.measure import regionprops\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image (you should replace 'your_image.png' with the actual image file path)\n",
    "img = cv2.imread('dataset/crack/Amalienstrasse_annotation.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Define a kernel for morphological operations\n",
    "kernel = np.ones((1, 2), np.uint8) \n",
    "dilated_image = cv2.dilate(img, kernel, iterations=1)\n",
    "eroded_image = cv2.erode(dilated_image, kernel, iterations=1)\n",
    "\n",
    "# Perform connected component analysis to label regions\n",
    "# (Assuming you have the connected component analysis code as mentioned earlier)\n",
    "labeled_image = connected_component_analysis(eroded_image)\n",
    "\n",
    "# Perform thinning using skimage's skeletonize function\n",
    "thinned_image = skeletonize(labeled_image)\n",
    "\n",
    "# Save and display the thinned crack image\n",
    "plt.imsave('thinned_crack.png', thinned_image, cmap='gray')\n",
    "plt.imshow(thinned_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Implement a function to compute the length of the detected cracks in the test set. Report the lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Length of Detected Cracks: 1174.4133365154266 pixels\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.morphology import skeletonize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the thinned crack image (you should replace 'thinned_crack.png' with your actual thinned image file path)\n",
    "thinned_image = cv2.imread('thinned_crack.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "def compute_crack_length(thinned_image):\n",
    "    # Threshold the image to obtain the crack lines\n",
    "    _, binary_image = cv2.threshold(thinned_image, 1, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours of the crack lines\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Initialize a variable to store the total length of detected cracks\n",
    "    total_length = 0\n",
    "    \n",
    "    # Iterate through the contours and calculate the length of each\n",
    "    for contour in contours:\n",
    "        length = cv2.arcLength(contour, closed=False)\n",
    "        total_length += length\n",
    "    \n",
    "    return total_length\n",
    "\n",
    "# Call the function to compute the length of detected cracks\n",
    "crack_length = compute_crack_length(thinned_image)\n",
    "\n",
    "# Print the total length of detected cracks\n",
    "print(f\"Total Length of Detected Cracks: {crack_length} pixels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full code of Classifier for detection crack or no-crack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.measure import regionprops\n",
    "\n",
    "# Function to perform preprocessing on the input image\n",
    "def preprocess_image(image_path, threshold_value=90):\n",
    "    # Read the input image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply adaptive thresholding to obtain a binary image\n",
    "    binary_image = cv2.adaptiveThreshold(\n",
    "        gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2\n",
    "    )\n",
    "\n",
    "    return binary_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create feature vectors for crack detection\n",
    "def create_feature_vector(binary_image, labeled_image, ground_truth_image):\n",
    "    feature_vectors = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate through each labeled region\n",
    "    for region in regionprops(labeled_image):\n",
    "        # Extract region properties\n",
    "        area = region.area\n",
    "        perimeter = region.perimeter\n",
    "\n",
    "        # Check if major_axis_length is zero before calculating the aspect ratio\n",
    "        if region.major_axis_length != 0:\n",
    "            aspect_ratio = region.minor_axis_length / region.major_axis_length\n",
    "        else:\n",
    "            aspect_ratio = 0.0  # Handle division by zero case\n",
    "\n",
    "        # Calculate circularity (check for zero perimeter to avoid division by zero)\n",
    "        if perimeter != 0:\n",
    "            circularity = 4 * np.pi * (area / (perimeter**2))\n",
    "        else:\n",
    "            circularity = 0.0  # Handle division by zero case\n",
    "\n",
    "        # Extract centroid coordinates\n",
    "        centroid_x, centroid_y = region.centroid\n",
    "\n",
    "        # Calculate distance from the center of the image\n",
    "        image_center_x, image_center_y = labeled_image.shape[1] / 2, labeled_image.shape[0] / 2\n",
    "        distance_to_center = np.sqrt((centroid_x - image_center_x)**2 + (centroid_y - image_center_y)**2)\n",
    "\n",
    "        # Determine if the region is a crack based on ground truth\n",
    "        x, y = int(centroid_x), int(centroid_y)\n",
    "        is_crack = ground_truth_image[y, x] == 255\n",
    "\n",
    "        # Create a feature vector\n",
    "        feature_vector = [area, perimeter, aspect_ratio, circularity, centroid_x, centroid_y, distance_to_center]\n",
    "\n",
    "        # Append the feature vector and label to lists\n",
    "        feature_vectors.append(feature_vector)\n",
    "        labels.append(is_crack)\n",
    "\n",
    "    return feature_vectors, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify regions as crack or non-crack using a classifier\n",
    "def classify_regions(feature_vectors, classifier, area_threshold=1000, aspect_ratio_threshold=0.6, circularity_threshold=0.6):\n",
    "    classified_regions = []\n",
    "\n",
    "    for i, region_feature_vector in enumerate(feature_vectors):\n",
    "        area, _, aspect_ratio, circularity, _, _, _ = region_feature_vector\n",
    "\n",
    "        if (\n",
    "            area >= area_threshold and\n",
    "            aspect_ratio >= aspect_ratio_threshold and\n",
    "            circularity >= circularity_threshold\n",
    "        ):\n",
    "            classified_regions.append((i, 'Crack'))\n",
    "        else:\n",
    "            classified_regions.append((i, 'Non-Crack'))\n",
    "\n",
    "    return classified_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region 0 is classified as Non-Crack\n"
     ]
    }
   ],
   "source": [
    "# Main function to process an input image\n",
    "def process_input_image(image_path):\n",
    "    # Preprocess the input image\n",
    "    binary_image = preprocess_image(image_path)\n",
    "\n",
    "    # Perform morphological operations and thinning\n",
    "    kernel = np.ones((10, 10), np.uint8)\n",
    "    dilated_image = cv2.dilate(binary_image, kernel, iterations=1)\n",
    "    eroded_image = cv2.erode(dilated_image, kernel, iterations=1)\n",
    "    closing_image = cv2.morphologyEx(eroded_image, cv2.MORPH_CLOSE, kernel)\n",
    "    thinned_image = skeletonize(closing_image)\n",
    "\n",
    "    # Load the labeled image (result from connected component analysis)\n",
    "    labeled_image = thinned_image.astype(np.uint8)\n",
    "\n",
    "    # Load the ground truth image (assuming white pixels represent cracks)\n",
    "    ground_truth_image = cv2.imread(\"After Streched Image.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Create feature vectors and labels\n",
    "    feature_vectors, labels = create_feature_vector(labeled_image, labeled_image, ground_truth_image)\n",
    "\n",
    "    # Load or train your classifier (you can replace this with your classifier)\n",
    "    classifier = ...  # Load or create your classifier here\n",
    "\n",
    "    # Classify regions as crack or non-crack\n",
    "    classified_regions = classify_regions(feature_vectors, classifier)\n",
    "\n",
    "    return classified_regions\n",
    "\n",
    "# Input image path (change this to the path of your input image)\n",
    "input_image_path = \"After Morphological Operations.png\"\n",
    "\n",
    "# Process the input image and get the classified regions\n",
    "results = process_input_image(input_image_path)\n",
    "\n",
    "# Print the results\n",
    "for i, result in results:\n",
    "    print(f\"Region {i} is classified as {result}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
